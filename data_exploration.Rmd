---
title: "Data Exploration of Tweets"
author: "Yuki Nagae"
output: html_document
---

# Data Exploration of Tweets

## Load Dataset

```{r setup, include=FALSE}
library(tidytext)
library(dplyr)
library(stringr)
library(wordcloud)
library(ggplot2)
```

```{r}
path <- "./data/"
train <- read.delim(paste0(path, "train.tsv"), header = FALSE, sep = " ")
```

```{r}
train_df <- data_frame(word = train$V1, type = train$V2)
train_df <- train_df %>% mutate(tweet = cumsum(str_detect(word, regex("^BOS"))))
```

## Data Exploration

### Identification of types

| Attribute  | Type     | Measured Value               | Description           |
|:-----------|:---------|:-----------------------------|:----------------------|
| word       | nominal  | BOS, @foo, they, will, be, all, done, by, Sunday, EOS | tokenized words and special words (BOS = beginning of sentence, EOS = end of sentence)
| NER type   | nominal  | O (other), B-person, I-person, B-geo-loc, I-geo-loc, B-other, I-other, B-company, I-company, B-facility, I-facility, B-product, I-product, B-musicartist, I-musicartist, B-sportsteam, I-sportsman, B-tvshow, I-tvshow, B-moview, I-movie, OBOS | named entities
    

### Identification of summarising properties (histgram, box plot etc)

the count the number of types

```{r}
train_df %>% count(type, sort=TRUE)
```

ggplot for the count of the number of types (very sparse)

```{r}
train_df %>% count(type, sort=TRUE) %>%
             mutate(type = reorder(type, n)) %>%
             ggplot(aes(type, n)) + geom_col() + coord_flip()
```

wordcloud visualization

```{r}
train_df %>% count(type) %>% with(wordcloud(type, n, max.words = 100))
```


### Identification of

* missing values
* outliers
* clusters
* interesting attributes


### Optional
* how many tweets?

```{r}
max(train_df$tweet)
```

* how many words for each tweet?

```{r}
train_df %>% group_by(tweet) %>% summarize(words = n())
```

```{r}
summary(train_df %>% group_by(tweet) %>% summarize(words = n()))
```

* top 30 words

```{r}
train_df %>% count(word, sort=TRUE) %>%
             filter(word != 'BOS') %>%
             filter(word != 'EOS') %>%
             top_n(30) %>%
             mutate(word = reorder(word, n)) %>%
             ggplot(aes(word, n)) + geom_col() + coord_flip()
```


## Data Pre-processing

* lower case (?)
* remove stop words (?)
* separated by BOS ~ EOS (different tweets)
* n-grams (maybe trigrams or 5-grams)

## Some tasks

* noun-phrase chunking
* POS tagging

## Named Entities

* Person
* Location
* Organization
* more?

## Modeling Techniques

* n-grams
* n-grams + Word2Vec
* n-grams + GloVe
* n-grams + SVM
* n-grams + KNN
* Stanford NLP tool (optional)

## References

* [Text Mining with R](http://tidytextmining.com)
